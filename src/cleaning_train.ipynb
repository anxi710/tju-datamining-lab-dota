{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### objective清洗v1.0\n",
    "按队伍和事件进行统计，并进行归一化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 加载数据\n",
    "file_path_objective = 'objective_table_train.csv'  # 原始 CSV 文件路径\n",
    "objective_data = pd.read_csv(file_path_objective)\n",
    "\n",
    "# 定义八种事件类型\n",
    "event_types = [\n",
    "    'CHAT_MESSAGE_BARRACKS_KILL',\n",
    "    'CHAT_MESSAGE_FIRSTBLOOD',\n",
    "    'CHAT_MESSAGE_DENIED_AEGIS',\n",
    "    'CHAT_MESSAGE_TOWER_KILL',\n",
    "    'CHAT_MESSAGE_AEGIS',\n",
    "    'CHAT_MESSAGE_ROSHAN_KILL',\n",
    "    'CHAT_MESSAGE_TOWER_DENY',\n",
    "    'CHAT_MESSAGE_AEGIS_STOLEN'\n",
    "]\n",
    "\n",
    "# 初始化 Radiant 和 Dire 的统计列\n",
    "radiant_cols = [f'radiant_{event}' for event in event_types]\n",
    "dire_cols = [f'dire_{event}' for event in event_types]\n",
    "result_cols = radiant_cols + dire_cols\n",
    "\n",
    "# 创建统计结果的 DataFrame\n",
    "objective_result = pd.DataFrame(columns=result_cols)\n",
    "\n",
    "# 遍历每一局比赛的事件\n",
    "for index, row in objective_data.iterrows():\n",
    "    # 初始化当前局的统计数据\n",
    "    stats = {col: 0 for col in result_cols}\n",
    "\n",
    "    # 遍历每一列 (objective-*-type, objective-*-player_slot, objective-*-team)\n",
    "    for i in range(1, 44):\n",
    "        type_col = f'objective-{i}-type'\n",
    "        slot_col = f'objective-{i}-player_slot'\n",
    "        team_col = f'objective-{i}-team'\n",
    "\n",
    "        # 确保事件类型列存在\n",
    "        if type_col in row:\n",
    "            event_type = row[type_col]\n",
    "            player_slot = row[slot_col] if slot_col in row else None\n",
    "            team = row[team_col] if team_col in row else None\n",
    "\n",
    "            # 判断事件类型是否有效\n",
    "            if event_type in event_types:\n",
    "                if player_slot is not None and not pd.isna(player_slot):  # 如果 player_slot 存在\n",
    "                    if 0 <= player_slot <= 4:  # Radiant\n",
    "                        stats[f'radiant_{event_type}'] += 1\n",
    "                    elif 128 <= player_slot <= 132:  # Dire\n",
    "                        stats[f'dire_{event_type}'] += 1\n",
    "                elif team is not None and not pd.isna(team):  # 如果 player_slot 为空，使用 team 判断\n",
    "                    if team == 2:  # Radiant\n",
    "                        stats[f'radiant_{event_type}'] += 1\n",
    "                    elif team == 3:  # Dire\n",
    "                        stats[f'dire_{event_type}'] += 1\n",
    "\n",
    "    # 将统计数据添加到结果数据框\n",
    "    objective_result = pd.concat([objective_result, pd.DataFrame([stats])], ignore_index=True)\n",
    "\n",
    "# 填充缺失值为 0\n",
    "objective_result.fillna(0, inplace=True)\n",
    "objective_result.to_csv('objective_statistics.csv', index=False)\n",
    "print(\"合并后的大表已保存为 'objective_statistics.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "file_path = 'objective_statistics.csv'\n",
    "objective_data = pd.read_csv(file_path)\n",
    "\n",
    "# 初始化归一化器\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 对所有数值列进行归一化\n",
    "numerical_columns = objective_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "objective_data[numerical_columns] = scaler.fit_transform(objective_data[numerical_columns])\n",
    "\n",
    "# 保存归一化后的数据\n",
    "output_csv_path = 'objective_statistics_normalized.csv'\n",
    "objective_data.to_csv(output_csv_path, index=False)\n",
    "print(f\"归一化后的数据已保存为: {output_csv_path}\")\n",
    "\n",
    "# 查看结果\n",
    "print(objective_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### player清洗v2.0\n",
    "删除obs、obs_log和sen_log  \n",
    "计算obs_left_log和sen_left_log的长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 player_table_deleted.csv 数据\n",
    "file_path_player = 'players_table_train_newest.csv'\n",
    "player_table_data = pd.read_csv(file_path_player)\n",
    "\n",
    "# 定义需要处理的日志列\n",
    "log_columns = [\n",
    "    'obs_left_log',\n",
    "    'obs_log',\n",
    "    'sen_left_log',\n",
    "    'sen_log',\n",
    "    'obs'\n",
    "]\n",
    "\n",
    "for player_num in range(1, 11):\n",
    "    # 构造该玩家的相关列名\n",
    "    player_cols = [f'players-{player_num}-{col}' for col in log_columns]\n",
    "\n",
    "    # 对每个列进行处理\n",
    "    for col in player_cols:\n",
    "        if col in player_table_data.columns:\n",
    "            # 如果是 players-1-obs_log、players-1-sen_log 或 players-1-obs 列直接删除\n",
    "            if (col.endswith('obs_log') or col.endswith('sen_log') or col.endswith('obs')) and 'left_log' not in col:\n",
    "                player_table_data.drop(columns=[col], inplace=True)\n",
    "            # 如果是日志列 (包含 'log'，但不是 obs_log 或 sen_log)\n",
    "            elif 'log' in col:\n",
    "                # 统计日志条目数：直接统计 `{` 的个数\n",
    "                player_table_data[col] = player_table_data[col].apply(\n",
    "                    lambda x: x.count('{') if isinstance(x, str) and x != '[]' else 0\n",
    "                )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "清除空值，将xp相加  \n",
    "非数字类型映射(randomed列的TRUE和FALSE进行布尔映射)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填充空值为 0\n",
    "player_table_data.fillna(0, inplace=True)\n",
    "\n",
    "# 替换布尔值\n",
    "player_table_data.replace({False: 0, True: 1}, inplace=True)\n",
    "\n",
    "# 遍历每个玩家的 xp_reasons 列进行处理\n",
    "for player_num in range(1, 11):\n",
    "    # 构造当前玩家的 xp_reasons 列名\n",
    "    reason_cols = [f'players-{player_num}-xp_reasons-{i}' for i in range(4)]\n",
    "    new_col_name = f'players-{player_num}-xp'  # 新列名\n",
    "\n",
    "    # 检查是否所有列存在\n",
    "    if all(col in player_table_data.columns for col in reason_cols):\n",
    "        # 计算总和\n",
    "        player_table_data[new_col_name] = player_table_data[reason_cols].sum(axis=1)\n",
    "\n",
    "        # 找到原始位置索引\n",
    "        first_col_index = player_table_data.columns.get_loc(reason_cols[0])\n",
    "\n",
    "        # 删除原始 xp_reasons 列\n",
    "        player_table_data.drop(columns=reason_cols, inplace=True)\n",
    "\n",
    "        # 调整列顺序，将新列插入到原始位置\n",
    "        cols = player_table_data.columns.tolist()\n",
    "        cols.insert(first_col_index, cols.pop(cols.index(new_col_name)))\n",
    "        player_table_data = player_table_data[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "观察数据中0的比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置阈值\n",
    "threshold = 0.8\n",
    "\n",
    "# 计算每列中值为 0 的比例\n",
    "zero_ratio = (player_table_data == 0).mean()\n",
    "\n",
    "# 筛选出值为 0 比例超过阈值的列\n",
    "columns_with_high_zero_ratio = zero_ratio[zero_ratio > threshold].index.tolist()\n",
    "\n",
    "# 输出这些列的名称和比例\n",
    "columns_with_high_zero_ratio_info = zero_ratio[zero_ratio > threshold]\n",
    "\n",
    "# 查看列名及其对应的 0 的比例\n",
    "print(f\"值为 0 的比例超过 {threshold * 100}% 的列有 {len(columns_with_high_zero_ratio)} 列：\")\n",
    "print(columns_with_high_zero_ratio_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算KDA,若Deaths=0，则直接k+a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):  # 针对 player-1 到 player-10\n",
    "    kills_col = f'players-{i}-kills'\n",
    "    assists_col = f'players-{i}-assists'\n",
    "    deaths_col = f'players-{i}-deaths'\n",
    "    kda_col = f'players-{i}-KDA'\n",
    "\n",
    "    # 确保特征列存在\n",
    "    if kills_col in player_table_data.columns and assists_col in player_table_data.columns and deaths_col in player_table_data.columns:\n",
    "        # 计算 KDA\n",
    "        player_table_data[kda_col] = player_table_data.apply(\n",
    "            lambda row: row[kills_col] + row[assists_col] if row[deaths_col] == 0\n",
    "            else (row[kills_col] + row[assists_col]) / row[deaths_col], axis=1\n",
    "        )\n",
    "    else:\n",
    "        print(f\"缺少 {kills_col}, {assists_col}, 或 {deaths_col} 列，无法计算 KDA。\")\n",
    "# 检查结果\n",
    "print(\"计算后的玩家数据：\")\n",
    "print(player_table_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算两队kills总和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiant_kills_cols = [f'players-{i}-kills' for i in range(1, 6)]\n",
    "dire_kills_cols = [f'players-{i}-kills' for i in range(6, 11)]\n",
    "\n",
    "# 检查列是否存在\n",
    "missing_radiant_cols = [col for col in radiant_kills_cols if col not in player_table_data.columns]\n",
    "missing_dire_cols = [col for col in dire_kills_cols if col not in player_table_data.columns]\n",
    "\n",
    "if missing_radiant_cols:\n",
    "    print(f\"缺失 Radiant 的特征列: {missing_radiant_cols}\")\n",
    "if missing_dire_cols:\n",
    "    print(f\"缺失 Dire 的特征列: {missing_dire_cols}\")\n",
    "\n",
    "# 确保所有列存在后计算\n",
    "if not missing_radiant_cols and not missing_dire_cols:\n",
    "    # Radiant 队伍的 kills 总和\n",
    "    player_table_data['Radiant-kills'] = player_table_data[radiant_kills_cols].sum(axis=1)\n",
    "\n",
    "    # Dire 队伍的 kills 总和\n",
    "    player_table_data['Dire-kills'] = player_table_data[dire_kills_cols].sum(axis=1)\n",
    "\n",
    "    # 查看结果\n",
    "    print(\"计算后的玩家数据：\")\n",
    "    print(player_table_data[['Radiant-kills', 'Dire-kills']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查空值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查 player_table_data 中的空值\n",
    "missing_values = player_table_data.isnull()\n",
    "\n",
    "# 获取含有空值的具体位置\n",
    "missing_locations = missing_values.stack()[missing_values.stack()].index.tolist()\n",
    "\n",
    "# 输出空值的总数和具体位置\n",
    "missing_count = len(missing_locations)\n",
    "print(f\"总共有 {missing_count} 个空值，具体位置如下：\")\n",
    "print(missing_locations[:10])  # 显示前10个位置，防止输出过长\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看一下异常值的比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 筛选出所有玩家的数据特征列并按特征类型进行分组\n",
    "features = set([col.split('-')[-1] for col in player_table_data.columns if col.startswith('players-')])\n",
    "anomalies_info_all_players = {}\n",
    "\n",
    "# 遍历所有特征\n",
    "for feature in features:\n",
    "    # 收集所有玩家对应特征的数据\n",
    "    feature_columns = [f'players-{player_num}-{feature}' for player_num in range(1, 11) if f'players-{player_num}-{feature}' in player_table_data.columns]\n",
    "    combined_data = pd.concat([player_table_data[col].dropna() for col in feature_columns])\n",
    "\n",
    "    # 确保数据为数值类型\n",
    "    if combined_data.dtype in ['float64', 'int64']:\n",
    "        # 计算 Q1 和 Q3\n",
    "        Q1 = combined_data.quantile(0.25)\n",
    "        Q3 = combined_data.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # 计算上下界\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # 计算异常值数量和比例\n",
    "        total_values = len(combined_data)\n",
    "        anomalies = ((combined_data < lower_bound) | (combined_data > upper_bound)).sum()\n",
    "        anomalies_ratio = anomalies / total_values\n",
    "\n",
    "        # 存储结果\n",
    "        anomalies_info_all_players[f'player_{feature}'] = {\n",
    "            'total_values': total_values,\n",
    "            'anomalies': anomalies,\n",
    "            'anomalies_ratio': anomalies_ratio,\n",
    "            'lower_bound': lower_bound,\n",
    "            'upper_bound': upper_bound,\n",
    "            'Q1': Q1,\n",
    "            'Q3': Q3\n",
    "        }\n",
    "\n",
    "# 转换为 DataFrame\n",
    "anomalies_df_all_players = pd.DataFrame.from_dict(anomalies_info_all_players, orient='index')\n",
    "\n",
    "# 显示异常值信息\n",
    "print(anomalies_df_all_players.head())\n",
    "\n",
    "# 可视化异常值比例\n",
    "anomalies_df_all_players['anomalies_ratio'].sort_values(ascending=False).plot(\n",
    "    kind='bar', figsize=(14, 7), title='Anomalies Ratio for All Features Across All Players')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Anomalies Ratio')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creeps_stacked sen_placed towers_killed异常值比例较高  \n",
    "再看一下数据分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "all_features = set(col.split('-')[-1] for col in player_table_data.columns if col.startswith('players-'))\n",
    "\n",
    "# 绘制所有特征的箱线图\n",
    "plt.figure(figsize=(20, len(all_features) * 2))\n",
    "for i, feature in enumerate(sorted(all_features), start=1):\n",
    "    plt.subplot((len(all_features) + 2) // 3, 3, i)  # 按 3 列布局，动态计算行数\n",
    "    \n",
    "    # 合并所有玩家的该特征数据\n",
    "    feature_columns = [f'players-{player_num}-{feature}' for player_num in range(1, 11) if f'players-{player_num}-{feature}' in player_table_data.columns]\n",
    "    combined_feature_data = pd.concat([player_table_data[col].dropna() for col in feature_columns])\n",
    "    \n",
    "    # 绘制箱线图\n",
    "    sns.boxplot(x=combined_feature_data)\n",
    "    plt.title(f'{feature} for All Players', fontsize=10)\n",
    "    plt.xlabel(feature, fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尝试处理异常值过多的特征，由于基本都偏右，选择对数变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 定义需要对数变换的特征列表\n",
    "features_to_log_transform = [\n",
    "    'deaths', 'denies', 'kills',\n",
    "    'max_health', 'max_hero_hit', 'max_mana',\n",
    "    'rune_pickups', 'nearby_creep_death_count'\n",
    "]\n",
    "\n",
    "# 对每个特征进行对数变换操作并覆盖原列\n",
    "for feature in features_to_log_transform:\n",
    "    for player_num in range(1, 11):\n",
    "        column_name = f'players-{player_num}-{feature}'\n",
    "        if column_name in player_table_data.columns:\n",
    "            # 对列进行对数变换，直接覆盖原列\n",
    "            player_table_data[column_name] = np.log1p(player_table_data[column_name])\n",
    "\n",
    "# 对 'deaths' 和 'denies' 进行异常值截断\n",
    "features_to_clip = ['deaths', 'denies']\n",
    "for feature in features_to_clip:\n",
    "    for player_num in range(1, 11):\n",
    "        column_name = f'players-{player_num}-{feature}'\n",
    "        if column_name in player_table_data.columns:\n",
    "            # 计算上下界值\n",
    "            Q1 = player_table_data[column_name].quantile(0.25)\n",
    "            Q3 = player_table_data[column_name].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            # 截断异常值\n",
    "            player_table_data[column_name] = player_table_data[column_name].clip(lower=lower_bound, upper=upper_bound)\n",
    "\n",
    "# 绘制处理后的列的箱式图\n",
    "plt.figure(figsize=(20, len(features_to_log_transform) * 2))\n",
    "for i, feature in enumerate(features_to_log_transform, start=1):\n",
    "    plt.subplot((len(features_to_log_transform) + 2) // 3, 3, i)  # 按 3 列布局，动态计算行数\n",
    "    \n",
    "    # 合并所有玩家的处理后列\n",
    "    feature_columns = [\n",
    "        f'players-{player_num}-{feature}' for player_num in range(1, 11) \n",
    "        if f'players-{player_num}-{feature}' in player_table_data.columns\n",
    "    ]\n",
    "    # 使用 ignore_index=True 避免索引冲突\n",
    "    combined_feature_data = pd.concat([player_table_data[col].dropna() for col in feature_columns], ignore_index=True)\n",
    "    \n",
    "    # 绘制箱线图\n",
    "    sns.boxplot(x=combined_feature_data)\n",
    "    plt.title(f'Boxplot of {feature} for All Players', fontsize=10)\n",
    "    plt.xlabel(feature, fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到大多数对数变换后效果不错，对一些特征进行截断后保留，效果较差的不采用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面进行归一化和标准化的处理，具体如下：  \n",
    "除了id和randomed外，其余列都进行了变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义需要归一化和标准化的特征列表\n",
    "features_to_normalize = [\n",
    "    'deaths', 'denies', 'kills', 'rune_pickups', 'creeps_stacked', 'gold',\n",
    "    'health', 'level', 'obs_left_log', 'observers_placed', 'sen_left_log',\n",
    "    'sen_placed', 'towers_killed', 'xp','lh','assists','camps_stacked','teamflight_participation','KDA'\n",
    "]\n",
    "\n",
    "features_to_standardize = [\n",
    "    'max_health', 'max_hero_hit', 'max_mana',\n",
    "    'nearby_creep_death_count', 'stuns'\n",
    "]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# 初始化标准化和归一化器\n",
    "scaler_normalize = MinMaxScaler()\n",
    "scaler_standardize = StandardScaler()\n",
    "\n",
    "# 对需要归一化的特征进行处理并替换原列\n",
    "for feature in features_to_normalize:\n",
    "    for player_num in range(1, 11):\n",
    "        column_name = f'players-{player_num}-{feature}'\n",
    "        if column_name in player_table_data.columns:\n",
    "            # 归一化处理并替换原列\n",
    "            player_table_data[[column_name]] = scaler_normalize.fit_transform(player_table_data[[column_name]])\n",
    "\n",
    "# 对需要标准化的特征进行处理并替换原列\n",
    "for feature in features_to_standardize:\n",
    "    for player_num in range(1, 11):\n",
    "        column_name = f'players-{player_num}-{feature}'\n",
    "        if column_name in player_table_data.columns:\n",
    "            # 标准化处理并替换原列\n",
    "            player_table_data[[column_name]] = scaler_standardize.fit_transform(player_table_data[[column_name]])\n",
    "\n",
    "# 保存更新后的数据为新的 CSV 文件\n",
    "output_csv_path = 'player_table_data_processed.csv'\n",
    "player_table_data.to_csv(output_csv_path, index=False)\n",
    "print(f\"处理后的数据已保存为: {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teamfight清洗v1.0\n",
    "计算总团战时间，求出总团战时间在总游戏时间的占比  \n",
    "提取并计算每支队伍在每局游戏中的damage、gold_delta、xp_delta的最大最小值及均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文件路径\n",
    "file_path_teamfights = 'teamfights_table_train.csv'\n",
    "file_path_main_table = 'main_table_train.csv'\n",
    "\n",
    "# 加载数据\n",
    "teamfights_data = pd.read_csv(file_path_teamfights)\n",
    "main_table_data = pd.read_csv(file_path_main_table)\n",
    "\n",
    "# 初始化结果 DataFrame\n",
    "processed_data = pd.DataFrame()\n",
    "\n",
    "# 计算总团战时间\n",
    "max_fights = 16  # 最多16次团战\n",
    "teamfight_duration_cols = []\n",
    "for i in range(1, max_fights + 1):\n",
    "    start_col = f'teamfights-{i}-start'\n",
    "    end_col = f'teamfights-{i}-end'\n",
    "    if start_col in teamfights_data.columns and end_col in teamfights_data.columns:\n",
    "        duration_col = f'teamfights-{i}-duration'\n",
    "        teamfights_data[duration_col] = teamfights_data[end_col] - teamfights_data[start_col]\n",
    "        teamfight_duration_cols.append(duration_col)\n",
    "\n",
    "# 总团战时间\n",
    "processed_data['total_teamfight_time'] = teamfights_data[teamfight_duration_cols].sum(axis=1)\n",
    "\n",
    "# 定义需要处理的列\n",
    "metrics = ['damage', 'gold_delta', 'xp_delta']\n",
    "teams = {'Radiant': range(1, 6), 'Dire': range(6, 11)}\n",
    "\n",
    "# 处理每种指标\n",
    "for metric in metrics:\n",
    "    for team, player_range in teams.items():\n",
    "        team_max = []\n",
    "        team_min = []\n",
    "        team_avg = []\n",
    "        for i in range(1, max_fights + 1):\n",
    "            fight_cols = [\n",
    "                f'teamfights-{i}-player-{player}-{metric}'\n",
    "                for player in player_range\n",
    "                if f'teamfights-{i}-player-{player}-{metric}' in teamfights_data.columns\n",
    "            ]\n",
    "            if fight_cols:\n",
    "                # 计算每次团战的统计值\n",
    "                team_max.append(teamfights_data[fight_cols].max(axis=1))\n",
    "                team_min.append(teamfights_data[fight_cols].min(axis=1))\n",
    "                team_avg.append(teamfights_data[fight_cols].mean(axis=1))\n",
    "\n",
    "        # 计算整局的统计值\n",
    "        if team_max:\n",
    "            processed_data[f'{team}_{metric}_max'] = pd.concat(team_max, axis=1).max(axis=1)\n",
    "            processed_data[f'{team}_{metric}_min'] = pd.concat(team_min, axis=1).min(axis=1)\n",
    "            processed_data[f'{team}_{metric}_avg'] = pd.concat(team_avg, axis=1).mean(axis=1)\n",
    "\n",
    "# 添加游戏时间和计算占比\n",
    "if 'game_time' in main_table_data.columns:\n",
    "    processed_data['game_time'] = main_table_data['game_time']\n",
    "    processed_data['teamfight_time_ratio'] = (\n",
    "        processed_data['total_teamfight_time'] / processed_data['game_time']\n",
    "    ).fillna(0)\n",
    "\n",
    "# 调整 `teamfight_time_ratio` 列的位置\n",
    "if 'total_teamfight_time' in processed_data.columns and 'teamfight_time_ratio' in processed_data.columns:\n",
    "    cols = processed_data.columns.tolist()\n",
    "    total_time_idx = cols.index('total_teamfight_time')\n",
    "    cols.insert(total_time_idx + 1, cols.pop(cols.index('teamfight_time_ratio')))\n",
    "    processed_data = processed_data[cols]\n",
    "\n",
    "# 保存最终结果\n",
    "output_path = 'teamfights_statistics.csv'\n",
    "processed_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"处理完成，结果已保存为 {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先观察数据（忽略空值，但是暂时不能删除或者置0）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# 加载数据\n",
    "processed_data = pd.read_csv('teamfights_statistics.csv')\n",
    "\n",
    "# 查看数据概览\n",
    "print(\"数据概览:\")\n",
    "print(processed_data.info())\n",
    "\n",
    "# 描述性统计\n",
    "print(\"\\n描述性统计:\")\n",
    "print(processed_data.describe())\n",
    "\n",
    "# 绘制箱线图并分析异常值（忽略空值）\n",
    "numeric_columns = processed_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "num_columns = len(numeric_columns)\n",
    "\n",
    "# 动态计算行数和列数\n",
    "cols = 3  # 每行显示的图表数量\n",
    "rows = math.ceil(num_columns / cols)  # 根据特征数量计算行数\n",
    "\n",
    "plt.figure(figsize=(cols * 5, rows * 5))  # 动态调整图表大小\n",
    "\n",
    "for i, column in enumerate(numeric_columns):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.boxplot(processed_data[column].dropna(), vert=False)  # 忽略空值绘制箱线图\n",
    "    plt.title(column)\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Box')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 异常值分析\n",
    "print(\"\\n异常值分析:\")\n",
    "for column in processed_data.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    q1 = processed_data[column].quantile(0.25)\n",
    "    q3 = processed_data[column].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    outliers = processed_data[(processed_data[column] < lower_bound) | (processed_data[column] > upper_bound)]\n",
    "    print(f\"\\n{column}列的异常值统计:\")\n",
    "    print(f\"下边界: {lower_bound}, 上边界: {upper_bound}\")\n",
    "    print(f\"异常值数量: {len(outliers)}（空值未计入）\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比例出现大于1的，检查一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找出所有包含 \"ratio\" 的列\n",
    "ratio_columns = [col for col in processed_data.columns if 'ratio' in col]\n",
    "\n",
    "# 检查并输出每个 \"ratio\" 列中大于 1 的行号和对应值\n",
    "for col in ratio_columns:\n",
    "    greater_than_one = processed_data[processed_data[col] > 1]  # 筛选大于 1 的数据\n",
    "    if not greater_than_one.empty:  # 如果存在大于 1 的数据\n",
    "        print(f\"\\n列 '{col}' 中大于 1 的数据:\")\n",
    "        for index, value in zip(greater_than_one.index, greater_than_one[col]):\n",
    "            print(f\"行号: {index}, 值: {value}\")\n",
    "    else:\n",
    "        print(f\"\\n列 '{col}' 中没有大于 1 的数据\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先观察数据（忽略空值，但是暂时不能删除或者置0）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "发现有些局数的game_time为0，才出现了inf的错误，这里全部将上述异常值置1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ratio_columns:\n",
    "    processed_data[col] = processed_data[col].apply(lambda x: 1 if x > 1 else x)\n",
    "\n",
    "# 检查替换结果\n",
    "for col in ratio_columns:\n",
    "    greater_than_one_count = (processed_data[col] > 1).sum()\n",
    "    print(f\"列 '{col}' 中剩余大于 1 的值数量: {greater_than_one_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查 teamfight_time_ratio 列是否存在，并统计值为 0 的个数\n",
    "if 'teamfight_time_ratio' in processed_data.columns:\n",
    "    zero_count = (processed_data['teamfight_time_ratio'] == 0).sum()\n",
    "    print(f\"'teamfight_time_ratio' 列中值为 0 的个数: {zero_count}\")\n",
    "else:\n",
    "    print(\"'teamfight_time_ratio' 列不存在于数据中。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面归一化和特征化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化归一化和标准化器\n",
    "min_max_scaler = MinMaxScaler()\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "# 拷贝数据用于操作，避免影响原始数据\n",
    "teamfight_data = processed_data.copy()\n",
    "\n",
    "# 队伍 damage 相关数据归一化\n",
    "damage_columns = [col for col in processed_data.columns if 'damage' in col]\n",
    "for col in damage_columns:\n",
    "    teamfight_data[col] = min_max_scaler.fit_transform(processed_data[[col]])\n",
    "\n",
    "# gold_delta 的 min 和 avg 标准化，max 归一化\n",
    "gold_delta_columns = [col for col in processed_data.columns if 'gold_delta' in col]\n",
    "for col in gold_delta_columns:\n",
    "    if 'min' in col or 'avg' in col:\n",
    "        teamfight_data[col] = standard_scaler.fit_transform(processed_data[[col]])\n",
    "    elif 'max' in col:\n",
    "        teamfight_data[col] = min_max_scaler.fit_transform(processed_data[[col]])\n",
    "\n",
    "# xp 相关数据归一化\n",
    "xp_columns = [col for col in processed_data.columns if 'xp' in col]\n",
    "for col in xp_columns:\n",
    "    teamfight_data[col] = min_max_scaler.fit_transform(processed_data[[col]])\n",
    "\n",
    "# 查看处理后的数据\n",
    "print(\"\\n归一化和标准化后的数据概览:\")\n",
    "print(teamfight_data.describe())\n",
    "\n",
    "# 保存结果到新文件\n",
    "teamfight_data.to_csv('teamfight_processed.csv', index=False)\n",
    "print(\"\\n处理后的数据已保存为 'teamfight_processed.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并所有表格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载五个表格\n",
    "main_table_deleted = pd.read_csv('main_table_train.csv')\n",
    "target_table_radiantwin = pd.read_csv('target_table_radiantwin_train.csv')\n",
    "player_table_data_processed = pd.read_csv('player_table_data_processed.csv')\n",
    "objective_statistics = pd.read_csv('objective_statistics_normalized.csv')\n",
    "teamfight_processed = pd.read_csv('teamfight_processed.csv')\n",
    "\n",
    "# 检查每张表的行数\n",
    "print(\"表格行数检查:\")\n",
    "print(f\"main_table_deleted: {main_table_deleted.shape[0]} 行\")\n",
    "print(f\"target_table_radiantwin: {target_table_radiantwin.shape[0]} 行\")\n",
    "print(f\"player_table_data_processed: {player_table_data_processed.shape[0]} 行\")\n",
    "print(f\"objective_statistics: {objective_statistics.shape[0]} 行\")\n",
    "print(f\"teamfight_processed: {teamfight_processed.shape[0]} 行\")\n",
    "\n",
    "# 确保所有表的行数一致\n",
    "if not all(df.shape[0] == main_table_deleted.shape[0] for df in [\n",
    "    target_table_radiantwin, player_table_data_processed, objective_statistics, teamfight_processed\n",
    "]):\n",
    "    raise ValueError(\"所有表格的行数不一致，无法直接拼接！\")\n",
    "\n",
    "# 水平合并表格（按列拼接）\n",
    "merged_data = pd.concat(\n",
    "    [main_table_deleted, target_table_radiantwin, player_table_data_processed, objective_statistics, teamfight_processed],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# 检查合并后的数据\n",
    "print(\"\\n合并后的数据概览:\")\n",
    "print(merged_data.info())\n",
    "\n",
    "# 保存合并后的数据\n",
    "merged_data.to_csv('train_data_v2.0.csv', index=False)\n",
    "print(\"合并后的大表已保存为 'Dota_data_v1.0.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
