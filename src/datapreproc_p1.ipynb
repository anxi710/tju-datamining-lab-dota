{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入软件包\n",
    "import os                  # 一些操作系统提供的 API\n",
    "import pandas as pd\n",
    "import ujson as json       # 用于读入 .json 文件\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 宏定义\n",
    "PATH_TO_RAW_DATA = \"../data\"\n",
    "PATH_TO_PROCESSED_DATA = \"./data\"\n",
    "PATH_TO_EXTRACTED_DATA = \"./data/extracted_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part0. 分析特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.readjsonl import read_matches\n",
    "from utils.getfeaturetree import get_keys_relation, build_tree, print_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取训练集中的所有键的关系\n",
    "key_rel_train = get_keys_relation(os.path.join(PATH_TO_RAW_DATA, \"train_matches.jsonl\"))\n",
    "tree = build_tree(key_rel_train)\n",
    "\n",
    "feature_tree_train_path = os.path.join(PATH_TO_PROCESSED_DATA, \"feature_tree_train.txt\")\n",
    "with open(feature_tree_train_path, \"w\") as f:\n",
    "    print_tree(tree, file=f)\n",
    "\n",
    "# 将树存储为 .json 文件\n",
    "feature_tree_train_json_path = os.path.join(PATH_TO_PROCESSED_DATA, \"feature_tree_train.json\")\n",
    "with open(feature_tree_train_json_path, \"w\") as f:\n",
    "    json.dump(tree, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取测试集中的所有键的关系\n",
    "key_rel_test = get_keys_relation(os.path.join(PATH_TO_RAW_DATA, \"test_matches.jsonl\"))\n",
    "tree = build_tree(key_rel_test)\n",
    "\n",
    "feature_tree_test_path = os.path.join(PATH_TO_PROCESSED_DATA, \"feature_tree_test.txt\")\n",
    "with open(feature_tree_test_path, \"w\") as f:\n",
    "    print_tree(tree, file=f)\n",
    "\n",
    "# 将树存储为 .json 文件\n",
    "feature_tree_test_json_path = os.path.join(PATH_TO_PROCESSED_DATA, \"feature_tree_test.json\")\n",
    "with open(feature_tree_test_json_path, \"w\") as f:\n",
    "    json.dump(tree, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_json_with_descriptions(json_file, excel_file, output_file):\n",
    "    \"\"\" 将 .xlsx 文件中的特征描述添加到 JSON 文件对应的特征中 \"\"\"\n",
    "    # 读取 JSON 文件\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # 读取 Excel 文件，第一列是 'feature'，第二列是 'description'，第三列是 'priority'\n",
    "    df = pd.read_excel(excel_file)\n",
    "\n",
    "    # 创建 feature 到 description 的映射\n",
    "    # feature : { description : \"\" }\n",
    "    feature_descriptions = {feature: {\"description\": description} for feature, description, _ in df.values}\n",
    "\n",
    "    # 递归更新 JSON 中的特征描述\n",
    "    def update_feature_descriptions(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for key, value in obj.items():\n",
    "                if key in feature_descriptions and value == {}:  # 如果该特征的值为空\n",
    "                    obj[key] = feature_descriptions[key]\n",
    "                else:\n",
    "                    update_feature_descriptions(value)           # 递归处理子对象\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                update_feature_descriptions(item)\n",
    "\n",
    "    # 更新 JSON 数据\n",
    "    update_feature_descriptions(data)\n",
    "\n",
    "    # 将更新后的 JSON 数据保存到新文件中\n",
    "    with open(output_file, 'w', encoding='utf-8') as f_out:\n",
    "        json.dump(data, f_out, indent=4, ensure_ascii=False)\n",
    "\n",
    "json_file_path   = os.path.join(PATH_TO_PROCESSED_DATA, \"feature_tree_test.json\")     # 原始 JSON 文件路径\n",
    "excel_file_path  = os.path.join(PATH_TO_PROCESSED_DATA, \"feature_descriptions.xlsx\")  # Excel 文件路径\n",
    "output_file_path = os.path.join(PATH_TO_PROCESSED_DATA, \"updated_feature.json\")  # 更新后的 JSON 文件路径\n",
    "\n",
    "update_json_with_descriptions(json_file_path, excel_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "手工标注 updated_features 得到 feature_description.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1. 特征选择及提取数据\n",
    "\n",
    "理解特征含义后，选择需要的特征、从原始数据中提取所需数据并进行一定的特征工程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确保输出路径存在\n",
    "if not os.path.exists(PATH_TO_EXTRACTED_DATA):\n",
    "    os.makedirs(PATH_TO_EXTRACTED_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.extractdata import extract_main\n",
    "\n",
    "df_main_table = extract_main(os.path.join(PATH_TO_RAW_DATA, 'train_matches.jsonl'))\n",
    "df_main_table.to_csv(os.path.join(PATH_TO_EXTRACTED_DATA, 'main_train.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.extractdata import extract_objectives\n",
    "\n",
    "df_objectives = extract_objectives(os.path.join(PATH_TO_RAW_DATA, 'train_matches.jsonl'))\n",
    "df_objectives.to_csv(os.path.join(PATH_TO_EXTRACTED_DATA, 'objectives_train.csv'), index=False)\n",
    "\n",
    "!sed -i 's/\\.0//g' ./data/extracted_data/objectives_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.extractdata import extract_targets\n",
    "\n",
    "df_targets = extract_targets(os.path.join(PATH_TO_RAW_DATA, 'train_matches.jsonl'))\n",
    "df_targets.to_csv(os.path.join(PATH_TO_EXTRACTED_DATA, 'targets_train.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.extractdata import extract_teamfights\n",
    "\n",
    "df_teamfights = extract_teamfights(os.path.join(PATH_TO_RAW_DATA, 'train_matches.jsonl'))\n",
    "df_teamfights.to_csv(os.path.join(PATH_TO_EXTRACTED_DATA, 'teamfights_train.csv'), index=False)\n",
    "\n",
    "!sed -i 's/\\.0,/,/g' ./data/extracted_data/teamfights_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.extractdata import extract_players\n",
    "\n",
    "df_players = extract_players(os.path.join(PATH_TO_RAW_DATA, 'train_matches.jsonl'))\n",
    "df_players.to_csv(os.path.join(PATH_TO_EXTRACTED_DATA, 'players_train_v2.csv'), index=False)\n",
    "\n",
    "!sed -i 's/\\.0,/,/g' ./data/extracted_data/players_train_v2.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 补充：数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析时序数据\n",
    "# 原始数据集中有部分以 _t 结尾的时序数据\n",
    "# 这些数据是在比赛的不同时间点记录的，我们可以使用这些数据来分析比赛的动态变化\n",
    "# 如：gold_t, lh_t, dn_t, xp_t 等\n",
    "# gold_t => 金币数，lh_t => 补刀数，dn_t => 反补数，xp_t => 经验值\n",
    "\n",
    "for match in read_matches('../data/train_matches.jsonl'):\n",
    "    for player in match['players']:\n",
    "        plt.plot(player['times'], player['gold_t'])\n",
    "    break\n",
    "\n",
    "plt.title('Gold change for all players')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
