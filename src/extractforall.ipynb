{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尝试提取全部的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Anaconda\\lib\\site-packages\\dask\\dataframe\\utils.py:13: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.一级标签提取——main table\n",
      "1.一级标签提取——main table提取成功\n",
      "2.提取objectives表格\n",
      "43\n",
      "2.提取objectives表格提取成功\n",
      "3.提取targets表格\n",
      "3.targets表格提取成功\n",
      "4.提取teamfights表格\n",
      "4.teamfights表格提取成功\n",
      "5.提取players表格\n",
      "5.players表格提取成功\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os #to access files\n",
    "import pandas as pd #to work with dataframes\n",
    "import numpy as np #just a tradition\n",
    "from sklearn.model_selection import StratifiedKFold #for cross-validation\n",
    "from sklearn.metrics import roc_auc_score #this is we are trying to increase\n",
    "import matplotlib.pyplot as plt #we will plot something at the end\n",
    "import seaborn as sns #same reason\n",
    "import lightgbm as lgb #the model we gonna use\n",
    "\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# 确保输出路径存在\n",
    "PATH_TO_DATA = '../data/'\n",
    "output_dir = os.path.join(PATH_TO_DATA, 'data_extract_new')\n",
    "os.makedirs(output_dir, exist_ok=True)  # 如果目录不存在，创建它\n",
    "\n",
    "print('1.一级标签提取——main table')\n",
    "def extract_non_nested_and_count_nested_keys(json_object):\n",
    "    \"\"\"\n",
    "    从JSON对象中提取所有不含嵌套属性的一级属性，\n",
    "    并对包含嵌套属性的一级属性统计其内部的数据数量。\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    for key, value in json_object.items():\n",
    "        # 如果属性不含嵌套（即不是dict或list），直接提取\n",
    "        if not isinstance(value, (dict, list)):\n",
    "            data[key] = value\n",
    "        # 如果属性是列表，统计其长度并添加统计列\n",
    "        elif isinstance(value, list):\n",
    "            data[f\"{key}_number\"] = len(value)\n",
    "        # 如果属性是字典类型，也记录其包含的键值数量\n",
    "        elif isinstance(value, dict):\n",
    "            data[f\"{key}_number\"] = len(value)\n",
    "    return data\n",
    "\n",
    "def jsonl_to_csv(jsonl_file_path, csv_file_path):\n",
    "    \"\"\"将JSONL文件转换为CSV文件，提取不含嵌套的一级属性，并统计嵌套属性的数量\"\"\"\n",
    "    with open(jsonl_file_path, 'r') as jsonl_file, open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        csv_writer = None\n",
    "        for line in jsonl_file:\n",
    "            json_object = json.loads(line.strip())\n",
    "            # 提取不含嵌套的一级属性和嵌套属性的数量\n",
    "            processed_data = extract_non_nested_and_count_nested_keys(json_object)\n",
    "            \n",
    "            # 删除不需要的列\n",
    "            for col_to_remove in ['objectives_number', 'players_number', 'targets_number']:\n",
    "                processed_data.pop(col_to_remove, None)\n",
    "            \n",
    "            # 初始化CSV写入器（仅在第一次循环时执行）\n",
    "            if csv_writer is None:\n",
    "                csv_writer = csv.DictWriter(csv_file, fieldnames=processed_data.keys())\n",
    "                csv_writer.writeheader()\n",
    "            # 写入CSV行\n",
    "            csv_writer.writerow(processed_data)\n",
    "\n",
    "# 使用\n",
    "PATH_TO_DATA = '../data/'\n",
    "jsonl_file_path = r\"E:\\同济本科作业相关\\DataMining\\Lab_Dota\\data\\train_matches.jsonl\"\n",
    "csv_file_path = os.path.join(PATH_TO_DATA, 'data_extract_new/main_table_deleted.csv')\n",
    "jsonl_to_csv(jsonl_file_path, csv_file_path)\n",
    "print('1.一级标签提取——main table提取成功')\n",
    "\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "print('2.提取objectives表格')\n",
    "def find_max_objectives(jsonl_file_path):\n",
    "    \"\"\"\n",
    "    遍历JSONL文件，找出所有行中objectives的最大数量。\n",
    "    \"\"\"\n",
    "    max_objectives = 0\n",
    "    with open(jsonl_file_path, 'r') as jsonl_file:\n",
    "        for line in jsonl_file:\n",
    "            json_object = json.loads(line.strip())\n",
    "            objectives_count = len(json_object.get(\"objectives\", []))\n",
    "            if objectives_count > max_objectives:\n",
    "                max_objectives = objectives_count\n",
    "    print(max_objectives)\n",
    "    return max_objectives\n",
    "\n",
    "def extract_objectives(json_object, max_objectives):\n",
    "    \"\"\"\n",
    "    从JSON对象中提取所有objectives数据，将每个objective展开成单独的列。\n",
    "    如果没有那么多objectives，则保留空值。\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    objectives = json_object.get(\"objectives\", [])\n",
    "    # 仅保留type、key、slot字段\n",
    "    keys_to_include = [\"type\", \"key\", \"slot\"]\n",
    "    for i in range(1, max_objectives + 1):\n",
    "        if i <= len(objectives):\n",
    "            objective = objectives[i - 1]\n",
    "            for key in keys_to_include:\n",
    "                column_name = f\"objective-{i}-{key}\"\n",
    "                data[column_name] = objective.get(key, \"\")\n",
    "        else:\n",
    "            for key in keys_to_include:\n",
    "                column_name = f\"objective-{i}-{key}\"\n",
    "                data[column_name] = \"\"\n",
    "    return data\n",
    "\n",
    "def jsonl_to_csv(jsonl_file_path, csv_file_path):\n",
    "    \"\"\"\n",
    "    将JSONL文件转换为CSV文件，提取并展开每一行中的所有objective数据。\n",
    "    \"\"\"\n",
    "    # 第一次遍历：找到最大的objectives数量\n",
    "    max_objectives = find_max_objectives(jsonl_file_path)\n",
    "    \n",
    "    with open(jsonl_file_path, 'r') as jsonl_file, open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        csv_writer = None\n",
    "        for line in jsonl_file:\n",
    "            json_object = json.loads(line.strip())\n",
    "            # 提取并展开objectives数据\n",
    "            processed_data = extract_objectives(json_object, max_objectives=max_objectives)\n",
    "            # 初始化CSV写入器（仅在第一次循环时执行）\n",
    "            if csv_writer is None:\n",
    "                csv_writer = csv.DictWriter(csv_file, fieldnames=processed_data.keys())\n",
    "                csv_writer.writeheader()\n",
    "            # 写入CSV行\n",
    "            csv_writer.writerow(processed_data)\n",
    "\n",
    "# 使用\n",
    "PATH_TO_DATA = '../data/'\n",
    "jsonl_file_path = r\"E:\\同济本科作业相关\\DataMining\\Lab_Dota\\data\\train_matches.jsonl\"\n",
    "csv_file_path = os.path.join(PATH_TO_DATA, 'data_extract_new/objective_table_deleted.csv')\n",
    "jsonl_to_csv(jsonl_file_path, csv_file_path)\n",
    "print('2.提取objectives表格提取成功')\n",
    "\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "print('3.提取targets表格')\n",
    "def extract_radiant_win(json_object):\n",
    "    \"\"\"\n",
    "    从JSON对象中提取radiant_win属性。\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    targets = json_object.get(\"targets\", {})\n",
    "    # 仅提取radiant_win字段\n",
    "    data[\"radiant_win\"] = targets.get(\"radiant_win\", \"\")\n",
    "    return data\n",
    "\n",
    "def jsonl_to_csv(jsonl_file_path, csv_file_path):\n",
    "    \"\"\"\n",
    "    将JSONL文件转换为CSV文件，仅提取radiant_win字段。\n",
    "    \"\"\"\n",
    "    with open(jsonl_file_path, 'r') as jsonl_file, open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        csv_writer = None\n",
    "        for line in jsonl_file:\n",
    "            json_object = json.loads(line.strip())\n",
    "            # 提取radiant_win字段\n",
    "            processed_data = extract_radiant_win(json_object)\n",
    "            # 初始化CSV写入器（仅在第一次循环时执行）\n",
    "            if csv_writer is None:\n",
    "                csv_writer = csv.DictWriter(csv_file, fieldnames=processed_data.keys())\n",
    "                csv_writer.writeheader()\n",
    "            # 写入CSV行\n",
    "            csv_writer.writerow(processed_data)\n",
    "\n",
    "# 使用\n",
    "PATH_TO_DATA = '../data/'\n",
    "jsonl_file_path = r\"E:\\同济本科作业相关\\DataMining\\Lab_Dota\\data\\train_matches.jsonl\"\n",
    "csv_file_path = os.path.join(PATH_TO_DATA, 'data_extract_new/target_table_radiantwin.csv')\n",
    "jsonl_to_csv(jsonl_file_path, csv_file_path)\n",
    "print('3.targets表格提取成功')\n",
    "\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "print('4.提取teamfights表格')\n",
    "def extract_teamfights(json_object, max_players):\n",
    "    \"\"\"\n",
    "    从JSON对象中提取teamfights数据，将每个teamfight和其下的player属性展开成单独的列。\n",
    "    删除players中的ability_uses, deaths, deaths_pos, item_uses, 和killed字段。\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    teamfights = json_object.get(\"teamfights\", [])\n",
    "\n",
    "    for i, teamfight in enumerate(teamfights, start=1):\n",
    "        # 提取teamfight的顶层字段\n",
    "        data[f\"teamfights-{i}-end\"] = teamfight.get(\"end\", \"\")\n",
    "        data[f\"teamfights-{i}-start\"] = teamfight.get(\"start\", \"\")\n",
    "        data[f\"teamfights-{i}-deaths\"] = teamfight.get(\"deaths\", \"\")\n",
    "        data[f\"teamfights-{i}-last_death\"] = teamfight.get(\"last_death\", \"\")\n",
    "\n",
    "        # 提取每个player的数据\n",
    "        players = teamfight.get(\"players\", [])\n",
    "        for j, player in enumerate(players, start=1):\n",
    "            # 删除不需要的字段，只保留以下字段\n",
    "            data[f\"teamfights-{i}-player-{j}-xp_delta\"] = player.get(\"xp_delta\", \"\")\n",
    "            data[f\"teamfights-{i}-player-{j}-damage\"] = player.get(\"damage\", \"\")\n",
    "            data[f\"teamfights-{i}-player-{j}-gold_delta\"] = player.get(\"gold_delta\", \"\")\n",
    "            data[f\"teamfights-{i}-player-{j}-healing\"] = player.get(\"healing\", \"\")\n",
    "            data[f\"teamfights-{i}-player-{j}-buybacks\"] = player.get(\"buybacks\", \"\")\n",
    "\n",
    "    return data\n",
    "\n",
    "def jsonl_to_csv(jsonl_file_path, csv_file_path):\n",
    "    \"\"\"\n",
    "    将JSONL文件转换为CSV文件，提取并展开每一行中的所有teamfights数据。\n",
    "    \"\"\"\n",
    "    all_fieldnames = set()\n",
    "    max_players = 0\n",
    "    \n",
    "    # 第一次遍历：确定最大玩家数量和完整字段名\n",
    "    with open(jsonl_file_path, 'r') as jsonl_file:\n",
    "        for line in jsonl_file:\n",
    "            json_object = json.loads(line.strip())\n",
    "            teamfights = json_object.get(\"teamfights\", [])\n",
    "            max_players = max(max_players, max(len(tf.get(\"players\", [])) for tf in teamfights) if teamfights else 0)\n",
    "            processed_data = extract_teamfights(json_object, max_players)\n",
    "            all_fieldnames.update(processed_data.keys())\n",
    "    \n",
    "    # 排序字段名，确保一致性\n",
    "    all_fieldnames = sorted(all_fieldnames)\n",
    "    \n",
    "    # 第二次遍历：将数据写入CSV文件\n",
    "    with open(jsonl_file_path, 'r') as jsonl_file, open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        csv_writer = csv.DictWriter(csv_file, fieldnames=all_fieldnames)\n",
    "        csv_writer.writeheader()\n",
    "        for line in jsonl_file:\n",
    "            json_object = json.loads(line.strip())\n",
    "            processed_data = extract_teamfights(json_object, max_players)\n",
    "            csv_writer.writerow(processed_data)\n",
    "\n",
    "# 使用\n",
    "PATH_TO_DATA = '../data/'\n",
    "jsonl_file_path = r\"E:\\同济本科作业相关\\DataMining\\Lab_Dota\\data\\train_matches.jsonl\"\n",
    "csv_file_path = os.path.join(PATH_TO_DATA, 'data_extract_new/teamfights_table_deleted.csv')\n",
    "jsonl_to_csv(jsonl_file_path, csv_file_path)\n",
    "print('4.teamfights表格提取成功')\n",
    "\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "print('5.提取players表格')\n",
    "def flatten_dict(data, prefix=\"\"):\n",
    "    \"\"\"\n",
    "    仅递归展开嵌套字典中需要展开的字段，避免过度拉平，保留指定字段为普通字段。\n",
    "    如果字段是字典，则展开为`prefix-key`的形式，如果是其他类型，则直接保存为值。\n",
    "    \"\"\"\n",
    "    flat_data = {}\n",
    "    for key, value in data.items():\n",
    "        new_key = f\"{prefix}-{key}\" if prefix else key\n",
    "        if isinstance(value, dict):\n",
    "            for sub_key, sub_value in value.items():\n",
    "                flat_data[f\"{new_key}-{sub_key}\"] = sub_value\n",
    "        else:\n",
    "            flat_data[new_key] = value\n",
    "    return flat_data\n",
    "\n",
    "def extract_players(json_object):\n",
    "    \"\"\"\n",
    "    从JSON对象中提取players数据，将每个player和其下的多级属性展开成单独的列。\n",
    "    删除指定字段，保留需要展开的字段，并处理多级嵌套。\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    players = json_object.get(\"players\", [])\n",
    "\n",
    "    for i, player in enumerate(players, start=1):\n",
    "        player_data = {}\n",
    "\n",
    "        # 仅保留需要的字段\n",
    "        required_fields = [\n",
    "            \"sen_placed\", \"sen_left_log\", \"kills\", \"obs_left_log\", \n",
    "            \"max_hero_hit\", \"obs_log\", \"max_mana\", \"creeps_stacked\", \n",
    "            \"xp_reasons\", \"randomed\", \"towers_killed\", \"health\", \n",
    "            \"rune_pickups\", \"level\", \"stuns\", \"deaths\", \"gold\",\n",
    "            \"nearby_creep_death_count\", \"denies\", \"observers_placed\", \n",
    "            \"sen_log\", \"hero_id\", \"max_health\"\n",
    "        ]\n",
    "        \n",
    "        for field in required_fields:\n",
    "            if field in player:\n",
    "                # 对 max_hero_hit 特殊处理，只保留 value 字段\n",
    "                if field == \"max_hero_hit\" and isinstance(player[field], dict):\n",
    "                    player_data[field] = player[field].get(\"value\", \"\")\n",
    "                else:\n",
    "                    player_data[field] = player[field]\n",
    "\n",
    "        # 展开需要的嵌套字典\n",
    "        flat_player_data = flatten_dict(player_data, prefix=f\"players-{i}\")\n",
    "        data.update(flat_player_data)\n",
    "\n",
    "    return data\n",
    "\n",
    "def jsonl_to_csv(jsonl_file_path, csv_file_path):\n",
    "    \"\"\"\n",
    "    将JSONL文件转换为CSV文件，提取并展开每一行中的所有players数据。\n",
    "    \"\"\"\n",
    "    all_fieldnames = set()\n",
    "    \n",
    "    # 第一次遍历：确定完整的字段名\n",
    "    with open(jsonl_file_path, 'r') as jsonl_file:\n",
    "        for line in jsonl_file:\n",
    "            json_object = json.loads(line.strip())\n",
    "            processed_data = extract_players(json_object)\n",
    "            all_fieldnames.update(processed_data.keys())\n",
    "    \n",
    "    # 排序字段名，确保一致性\n",
    "    all_fieldnames = sorted(all_fieldnames)\n",
    "    \n",
    "    # 第二次遍历：将数据写入CSV文件\n",
    "    with open(jsonl_file_path, 'r') as jsonl_file, open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        csv_writer = csv.DictWriter(csv_file, fieldnames=all_fieldnames)\n",
    "        csv_writer.writeheader()\n",
    "        for line in jsonl_file:\n",
    "            json_object = json.loads(line.strip())\n",
    "            processed_data = extract_players(json_object)\n",
    "            csv_writer.writerow(processed_data)\n",
    "\n",
    "# 使用\n",
    "PATH_TO_DATA = '../data/'\n",
    "jsonl_file_path = r\"E:\\同济本科作业相关\\DataMining\\Lab_Dota\\data\\train_matches.jsonl\"\n",
    "csv_file_path = os.path.join(PATH_TO_DATA, 'data_extract_new/players_table_deleted.csv')\n",
    "jsonl_to_csv(jsonl_file_path, csv_file_path)\n",
    "print('5.players表格提取成功')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "迭代，需要留player_slot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Anaconda\\lib\\site-packages\\dask\\dataframe\\utils.py:13: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.提取objectives表格\n",
      "43\n",
      "2.提取objectives表格提取成功\n"
     ]
    }
   ],
   "source": [
    "import os #to access files\n",
    "import pandas as pd #to work with dataframes\n",
    "import numpy as np #just a tradition\n",
    "from sklearn.model_selection import StratifiedKFold #for cross-validation\n",
    "from sklearn.metrics import roc_auc_score #this is we are trying to increase\n",
    "import matplotlib.pyplot as plt #we will plot something at the end\n",
    "import seaborn as sns #same reason\n",
    "import lightgbm as lgb #the model we gonna use\n",
    "\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# 确保输出路径存在\n",
    "PATH_TO_DATA = '../data/'\n",
    "output_dir = os.path.join(PATH_TO_DATA, 'data_extract_new')\n",
    "os.makedirs(output_dir, exist_ok=True)  # 如果目录不存在，创建它\n",
    "\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "print('2.提取objectives表格')\n",
    "def find_max_objectives(jsonl_file_path):\n",
    "    \"\"\"\n",
    "    遍历JSONL文件，找出所有行中objectives的最大数量。\n",
    "    \"\"\"\n",
    "    max_objectives = 0\n",
    "    with open(jsonl_file_path, 'r') as jsonl_file:\n",
    "        for line in jsonl_file:\n",
    "            json_object = json.loads(line.strip())\n",
    "            objectives_count = len(json_object.get(\"objectives\", []))\n",
    "            if objectives_count > max_objectives:\n",
    "                max_objectives = objectives_count\n",
    "    print(max_objectives)\n",
    "    return max_objectives\n",
    "\n",
    "def extract_objectives(json_object, max_objectives):\n",
    "    \"\"\"\n",
    "    从JSON对象中提取所有objectives数据，将每个objective展开成单独的列。\n",
    "    如果没有那么多objectives，则保留空值。\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    objectives = json_object.get(\"objectives\", [])\n",
    "    # 仅保留type、key、slot字段\n",
    "    keys_to_include = [\"type\", \"player_slot\",\"key\", \"slot\"]\n",
    "    for i in range(1, max_objectives + 1):\n",
    "        if i <= len(objectives):\n",
    "            objective = objectives[i - 1]\n",
    "            for key in keys_to_include:\n",
    "                column_name = f\"objective-{i}-{key}\"\n",
    "                data[column_name] = objective.get(key, \"\")\n",
    "        else:\n",
    "            for key in keys_to_include:\n",
    "                column_name = f\"objective-{i}-{key}\"\n",
    "                data[column_name] = \"\"\n",
    "    return data\n",
    "\n",
    "def jsonl_to_csv(jsonl_file_path, csv_file_path):\n",
    "    \"\"\"\n",
    "    将JSONL文件转换为CSV文件，提取并展开每一行中的所有objective数据。\n",
    "    \"\"\"\n",
    "    # 第一次遍历：找到最大的objectives数量\n",
    "    max_objectives = find_max_objectives(jsonl_file_path)\n",
    "    \n",
    "    with open(jsonl_file_path, 'r') as jsonl_file, open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        csv_writer = None\n",
    "        for line in jsonl_file:\n",
    "            json_object = json.loads(line.strip())\n",
    "            # 提取并展开objectives数据\n",
    "            processed_data = extract_objectives(json_object, max_objectives=max_objectives)\n",
    "            # 初始化CSV写入器（仅在第一次循环时执行）\n",
    "            if csv_writer is None:\n",
    "                csv_writer = csv.DictWriter(csv_file, fieldnames=processed_data.keys())\n",
    "                csv_writer.writeheader()\n",
    "            # 写入CSV行\n",
    "            csv_writer.writerow(processed_data)\n",
    "\n",
    "# 使用\n",
    "PATH_TO_DATA = '../data/'\n",
    "jsonl_file_path = r\"E:\\同济本科作业相关\\DataMining\\Lab_Dota\\data\\train_matches.jsonl\"\n",
    "csv_file_path = os.path.join(PATH_TO_DATA, 'data_extract_new/objective_table_deleted.csv')\n",
    "jsonl_to_csv(jsonl_file_path, csv_file_path)\n",
    "print('2.提取objectives表格提取成功')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
