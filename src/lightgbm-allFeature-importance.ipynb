{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目标：将全部的属性输入GBDT模型中，观察所有属性的重要性\n",
    "\n",
    "\n",
    "目标的可行性存疑：\n",
    "1、所有属性不可能被直接写入GBDT，必然存在很多的空值和无法数值化的值（字符串\n",
    "2、会出现很多TRUE一类的需要进一步预处理的值（这个TRUE在jsonl文件中到底是怎么表示的（是宏定义的数字1还是什么？\n",
    "目前的思路：\n",
    "1、我自己在jsonl提取的时候，首先就删掉一些应该不需要的(比如所有的chat字符串等等)，这个可以减少csv的文件大小+减少进入模型去跑特征重要性的时候需要的数据预处理复杂度\n",
    "2、进一步探讨……"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Anaconda\\lib\\site-packages\\dask\\dataframe\\utils.py:13: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import os #to access files\n",
    "import pandas as pd #to work with dataframes\n",
    "import numpy as np #just a tradition\n",
    "from sklearn.model_selection import StratifiedKFold #for cross-validation\n",
    "from sklearn.metrics import roc_auc_score #this is we are trying to increase\n",
    "import matplotlib.pyplot as plt #we will plot something at the end\n",
    "import seaborn as sns #same reason\n",
    "import lightgbm as lgb #the model we gonna use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从train_matches.jsonl中提取出所有的特征对应的所有数据项，成为一个csv文件\n",
    "\n",
    "！！！！这个代码是错误的，不要跑，无法提取出想要的csv 提取的很混乱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 定义输入 JSONL 文件和输出 CSV 文件的路径\u001b[39;00m\n\u001b[0;32m      5\u001b[0m PATH_TO_DATA \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 7\u001b[0m jsonl_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(PATH_TO_DATA,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_test.jsonl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m csv_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(PATH_TO_DATA,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflatten_json\u001b[39m(nested_json, parent_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import json\n",
    "import csv\n",
    "\n",
    "# 定义输入 JSONL 文件和输出 CSV 文件的路径\n",
    "PATH_TO_DATA = '../data/'\n",
    "\n",
    "jsonl_file_path = os.path.join(PATH_TO_DATA,'input_test.jsonl')\n",
    "csv_file_path = os.path.join(PATH_TO_DATA,'output_test.csv')\n",
    "\n",
    "def flatten_json(nested_json, parent_key='', sep='-'):\n",
    "    \"\"\"递归地展开嵌套的 JSON 对象，并使用指定的分隔符.\"\"\"\n",
    "    items = []\n",
    "    for k, v in nested_json.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_json(v, new_key, sep=sep).items())\n",
    "        elif isinstance(v, list):\n",
    "            # 对列表内的每个元素展开\n",
    "            for i, item in enumerate(v):\n",
    "                if isinstance(item, dict):\n",
    "                    items.extend(flatten_json(item, f\"{new_key}{sep}{i}\", sep=sep).items())\n",
    "                else:\n",
    "                    items.append((f\"{new_key}{sep}{i}\", item))\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "# 打开 JSONL 文件并读取数据\n",
    "with open(jsonl_file_path, 'r', encoding='utf-8') as jsonl_file:\n",
    "    # 读取 JSONL 文件中的每一行，并展开嵌套结构\n",
    "    data = [flatten_json(json.loads(line)) for line in jsonl_file]\n",
    "\n",
    "# 获取所有列名（字段）并写入 CSV 文件\n",
    "fieldnames = sorted({key for row in data for key in row.keys()})\n",
    "with open(csv_file_path, 'w', encoding='utf-8', newline='') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"数据已成功从 {jsonl_file_path} 转换为 {csv_file_path}，并展开了嵌套结构\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导出了一个近乎10G的大csv文件，但是遇到一定的问题\n",
    "1、文件过大，excel无法打开\n",
    "2、在两行json转csv的时候可以保证正确性，2G的转化的时候正确性存疑\n",
    "\n",
    "所以接下来写代码尝试只展示前三行csv\n",
    "\n",
    "！！！！配合上面出错的代码的验证程序，也不要跑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport pandas as pd\\n\\n# 读取CSV文件\\nPATH_TO_DATA = '../data/'\\ncsv_file_path = os.path.join(PATH_TO_DATA,'output_test.csv')\\n\\nfile_path = csv_file_path  # 请将 'your_file.csv' 替换为你的文件路径\\n#df = pd.read_csv(file_path)\\ndf = pd.read_csv(csv_file_path, nrows=4)\\n\\n# 展示表头和前三行数据\\ndf.head(3)\\n\\n# 将前三行写入一个新的CSV文件\\noutput_file_path = os.path.join(PATH_TO_DATA, 'output_first_three_rows_demo.csv')\\ndf.to_csv(output_file_path, index=False)\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "# 读取CSV文件\n",
    "PATH_TO_DATA = '../data/'\n",
    "csv_file_path = os.path.join(PATH_TO_DATA,'output_test.csv')\n",
    "\n",
    "file_path = csv_file_path  # 请将 'your_file.csv' 替换为你的文件路径\n",
    "#df = pd.read_csv(file_path)\n",
    "df = pd.read_csv(csv_file_path, nrows=4)\n",
    "\n",
    "# 展示表头和前三行数据\n",
    "df.head(3)\n",
    "\n",
    "# 将前三行写入一个新的CSV文件\n",
    "output_file_path = os.path.join(PATH_TO_DATA, 'output_first_three_rows_demo.csv')\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提取数据 \n",
    "将所有无折叠的一级标签提取出来  \n",
    "对有折叠的一级标题，提取其内部包含了几组元素，即提取出其长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "def extract_non_nested_and_count_nested_keys(json_object):\n",
    "    \"\"\"\n",
    "    从JSON对象中提取所有不含嵌套属性的一级属性，\n",
    "    并对包含嵌套属性的一级属性统计其内部的数据数量。\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    for key, value in json_object.items():\n",
    "        # 如果属性不含嵌套（即不是dict或list），直接提取\n",
    "        if not isinstance(value, (dict, list)):\n",
    "            data[key] = value\n",
    "        # 如果属性是列表，统计其长度并添加统计列\n",
    "        elif isinstance(value, list):\n",
    "            data[f\"{key}_number\"] = len(value)\n",
    "        # 如果属性是字典类型，也记录其包含的键值数量\n",
    "        elif isinstance(value, dict):\n",
    "            data[f\"{key}_number\"] = len(value)\n",
    "    return data\n",
    "\n",
    "def jsonl_to_csv(jsonl_file_path, csv_file_path):\n",
    "    \"\"\"将JSONL文件转换为CSV文件，提取不含嵌套的一级属性，并统计嵌套属性的数量\"\"\"\n",
    "    with open(jsonl_file_path, 'r') as jsonl_file, open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        csv_writer = None\n",
    "        for line in jsonl_file:\n",
    "            json_object = json.loads(line.strip())\n",
    "            # 提取不含嵌套的一级属性和嵌套属性的数量\n",
    "            processed_data = extract_non_nested_and_count_nested_keys(json_object)\n",
    "            # 初始化CSV写入器（仅在第一次循环时执行）\n",
    "            if csv_writer is None:\n",
    "                csv_writer = csv.DictWriter(csv_file, fieldnames=processed_data.keys())\n",
    "                csv_writer.writeheader()\n",
    "            # 写入CSV行\n",
    "            csv_writer.writerow(processed_data)\n",
    "\n",
    "# 使用\n",
    "PATH_TO_DATA = '../data/'\n",
    "jsonl_file_path = os.path.join(PATH_TO_DATA,'input_test.jsonl')\n",
    "csv_file_path = os.path.join(PATH_TO_DATA,'data_extract/main_table.csv')\n",
    "jsonl_to_csv(jsonl_file_path, csv_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提取objectives表格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "def find_max_objectives(jsonl_file_path):\n",
    "    \"\"\"\n",
    "    遍历JSONL文件，找出所有行中objectives的最大数量。\n",
    "    \"\"\"\n",
    "    max_objectives = 0\n",
    "    with open(jsonl_file_path, 'r') as jsonl_file:\n",
    "        for line in jsonl_file:\n",
    "            json_object = json.loads(line.strip())\n",
    "            objectives_count = len(json_object.get(\"objectives\", []))\n",
    "            if objectives_count > max_objectives:\n",
    "                max_objectives = objectives_count\n",
    "    print(max_objectives)\n",
    "    return max_objectives\n",
    "\n",
    "def extract_objectives(json_object, max_objectives):\n",
    "    \"\"\"\n",
    "    从JSON对象中提取所有objectives数据，将每个objective展开成单独的列。\n",
    "    如果没有那么多objectives，则保留空值。\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    objectives = json_object.get(\"objectives\", [])\n",
    "    for i in range(1, max_objectives + 1):\n",
    "        if i <= len(objectives):\n",
    "            objective = objectives[i - 1]\n",
    "            for key in [\"time\", \"type\", \"player_slot\", \"team\", \"key\", \"slot\"]:\n",
    "                column_name = f\"objective-{i}-{key}\"\n",
    "                data[column_name] = objective.get(key, \"\")\n",
    "        else:\n",
    "            for key in [\"time\", \"type\", \"player_slot\", \"team\", \"key\", \"slot\"]:\n",
    "                column_name = f\"objective-{i}-{key}\"\n",
    "                data[column_name] = \"\"\n",
    "    return data\n",
    "\n",
    "def jsonl_to_csv(jsonl_file_path, csv_file_path):\n",
    "    \"\"\"\n",
    "    将JSONL文件转换为CSV文件，提取并展开每一行中的所有objective数据。\n",
    "    \"\"\"\n",
    "    # 第一次遍历：找到最大的objectives数量\n",
    "    max_objectives = find_max_objectives(jsonl_file_path)\n",
    "    \n",
    "    with open(jsonl_file_path, 'r') as jsonl_file, open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        csv_writer = None\n",
    "        for line in jsonl_file:\n",
    "            json_object = json.loads(line.strip())\n",
    "            # 提取并展开objectives数据\n",
    "            processed_data = extract_objectives(json_object, max_objectives=max_objectives)\n",
    "            # 初始化CSV写入器（仅在第一次循环时执行）\n",
    "            if csv_writer is None:\n",
    "                csv_writer = csv.DictWriter(csv_file, fieldnames=processed_data.keys())\n",
    "                csv_writer.writeheader()\n",
    "            # 写入CSV行\n",
    "            csv_writer.writerow(processed_data)\n",
    "\n",
    "# 使用\n",
    "PATH_TO_DATA = '../data/'\n",
    "jsonl_file_path = os.path.join(PATH_TO_DATA,'input_test.jsonl')\n",
    "csv_file_path = os.path.join(PATH_TO_DATA,'data_extract/objective_table.csv')\n",
    "jsonl_to_csv(jsonl_file_path, csv_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同理，提取targets表格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def extract_targets(json_object):\n",
    "    data = {}\n",
    "    targets = json_object.get(\"targets\", {})\n",
    "    # 展开每个target属性\n",
    "    for key in [\"next_roshan_team\", \"radiant_win\", \"duration\", \"time_remaining\", \"game_time\"]:\n",
    "        data[key] = targets.get(key, \"\")\n",
    "    return data\n",
    "\n",
    "def jsonl_to_csv(jsonl_file_path, csv_file_path):\n",
    "    \"\"\"\n",
    "    将JSONL文件转换为CSV文件，提取并展开每一行中的所有target数据。\n",
    "     \"\"\"\n",
    "    with open(jsonl_file_path, 'r') as jsonl_file, open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        csv_writer = None\n",
    "        for line in jsonl_file:\n",
    "            json_object = json.loads(line.strip())\n",
    "             # 提取并展开targets数据\n",
    "            processed_data = extract_targets(json_object)\n",
    "            # 初始化CSV写入器（仅在第一次循环时执行）\n",
    "            if csv_writer is None:\n",
    "                csv_writer = csv.DictWriter(csv_file, fieldnames=processed_data.keys())\n",
    "                csv_writer.writeheader()\n",
    "            csv_writer.writerow(processed_data)\n",
    "\n",
    "# 使用\n",
    "PATH_TO_DATA = '../data/'\n",
    "jsonl_file_path = os.path.join(PATH_TO_DATA, 'input_test.jsonl')\n",
    "csv_file_path = os.path.join(PATH_TO_DATA, 'data_extract/target_table.csv')\n",
    "jsonl_to_csv(jsonl_file_path, csv_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同理，提取teamfights表格，其中，players涉及多级嵌套，将其嵌套展开单独成列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def extract_teamfights(json_object, max_players):\n",
    "    \"\"\"\n",
    "    从JSON对象中提取teamfights数据，将每个teamfight和其下的player属性展开成单独的列。\n",
    "    对于players中的多级字段（如ability_uses, item_uses等），保持为字典字符串。\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    teamfights = json_object.get(\"teamfights\", [])\n",
    "\n",
    "    for i, teamfight in enumerate(teamfights, start=1):\n",
    "        # 提取teamfight的顶层字段\n",
    "        data[f\"teamfights-{i}-end\"] = teamfight.get(\"end\", \"\")\n",
    "        data[f\"teamfights-{i}-start\"] = teamfight.get(\"start\", \"\")\n",
    "        data[f\"teamfights-{i}-deaths\"] = teamfight.get(\"deaths\", \"\")\n",
    "        data[f\"teamfights-{i}-last_death\"] = teamfight.get(\"last_death\", \"\")\n",
    "\n",
    "        # 提取每个player的数据\n",
    "        players = teamfight.get(\"players\", [])\n",
    "        for j, player in enumerate(players, start=1):\n",
    "            # 保持每个player的多级字段为字典字符串\n",
    "            data[f\"teamfights-{i}-player-{j}-ability_uses\"] = json.dumps(player.get(\"ability_uses\", {}))\n",
    "            data[f\"teamfights-{i}-player-{j}-deaths\"] = player.get(\"deaths\", \"\")\n",
    "            data[f\"teamfights-{i}-player-{j}-killed\"] = json.dumps(player.get(\"killed\", {}))\n",
    "            data[f\"teamfights-{i}-player-{j}-item_uses\"] = json.dumps(player.get(\"item_uses\", {}))\n",
    "            data[f\"teamfights-{i}-player-{j}-xp_delta\"] = player.get(\"xp_delta\", \"\")\n",
    "            data[f\"teamfights-{i}-player-{j}-damage\"] = player.get(\"damage\", \"\")\n",
    "            data[f\"teamfights-{i}-player-{j}-gold_delta\"] = player.get(\"gold_delta\", \"\")\n",
    "            data[f\"teamfights-{i}-player-{j}-deaths_pos\"] = json.dumps(player.get(\"deaths_pos\", {}))\n",
    "            data[f\"teamfights-{i}-player-{j}-healing\"] = player.get(\"healing\", \"\")\n",
    "            data[f\"teamfights-{i}-player-{j}-buybacks\"] = player.get(\"buybacks\", \"\")\n",
    "\n",
    "    return data\n",
    "\n",
    "def jsonl_to_csv(jsonl_file_path, csv_file_path):\n",
    "    \"\"\"\n",
    "    将JSONL文件转换为CSV文件，提取并展开每一行中的所有teamfights数据。\n",
    "    \"\"\"\n",
    "    all_fieldnames = set()\n",
    "    max_players = 0\n",
    "    \n",
    "    # 第一次遍历：确定最大玩家数量和完整字段名\n",
    "    with open(jsonl_file_path, 'r') as jsonl_file:\n",
    "        for line in jsonl_file:\n",
    "            json_object = json.loads(line.strip())\n",
    "            teamfights = json_object.get(\"teamfights\", [])\n",
    "            max_players = max(max_players, max(len(tf.get(\"players\", [])) for tf in teamfights) if teamfights else 0)\n",
    "            processed_data = extract_teamfights(json_object, max_players)\n",
    "            all_fieldnames.update(processed_data.keys())\n",
    "    \n",
    "    # 排序字段名，确保一致性\n",
    "    all_fieldnames = sorted(all_fieldnames)\n",
    "    \n",
    "    # 第二次遍历：将数据写入CSV文件\n",
    "    with open(jsonl_file_path, 'r') as jsonl_file, open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        csv_writer = csv.DictWriter(csv_file, fieldnames=all_fieldnames)\n",
    "        csv_writer.writeheader()\n",
    "        for line in jsonl_file:\n",
    "            json_object = json.loads(line.strip())\n",
    "            processed_data = extract_teamfights(json_object, max_players)\n",
    "            csv_writer.writerow(processed_data)\n",
    "\n",
    "# 使用\n",
    "PATH_TO_DATA = '../data/'\n",
    "jsonl_file_path = os.path.join(PATH_TO_DATA, 'input_test.jsonl')\n",
    "csv_file_path = os.path.join(PATH_TO_DATA, 'data_extract/teamfights_table.csv')\n",
    "jsonl_to_csv(jsonl_file_path, csv_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提取players表(二级缩进版本）\n",
    "即：如有缩进，提取到第二个缩进为止，其他暂时没有做进一步处理\n",
    "我的思考：\n",
    "1.涉及到time-key结构、名称-伤害-time结构的，是否可以变成数组？\n",
    "2.xxx_log和xxx是重复的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def flatten_dict(data, prefix=\"\"):\n",
    "    \"\"\"\n",
    "    仅递归展开嵌套字典中需要展开的字段，避免过度拉平，保留指定字段为普通字段。\n",
    "    如果字段是字典，则展开为`prefix-key`的形式，如果是其他类型，则直接保存为值。\n",
    "    \"\"\"\n",
    "    flat_data = {}\n",
    "    for key, value in data.items():\n",
    "        new_key = f\"{prefix}-{key}\" if prefix else key\n",
    "        if isinstance(value, dict) and key not in [\"killed\", \"obs\", \"purchase\", \"actions\"]:  # 不展开这些字段\n",
    "            for sub_key, sub_value in value.items():\n",
    "                flat_data[f\"{new_key}-{sub_key}\"] = sub_value\n",
    "        else:\n",
    "            flat_data[new_key] = value\n",
    "    return flat_data\n",
    "\n",
    "def extract_players(json_object):\n",
    "    \"\"\"\n",
    "    从JSON对象中提取players数据，将每个player和其下的多级属性展开成单独的列。\n",
    "    删除不需要的字段，保留需要展开的字段，并处理多级嵌套。\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    players = json_object.get(\"players\", [])\n",
    "\n",
    "    for i, player in enumerate(players, start=1):\n",
    "        player_data = {}\n",
    "\n",
    "        # 仅保留需要的字段\n",
    "        required_fields = [\n",
    "            \"hero_inventory\", \"sen_placed\", \"hero_stash\", \"sen_left_log\", \"kills\", \"purchase_log\",\n",
    "            \"obs_left_log\", \"max_hero_hit\", \"runes_log\", \"buyback_log\", \"obs_log\", \"max_mana\",\n",
    "             \"creeps_stacked\", \"killed\", \"obs\", \"purchase\", \"y\", \"max_health\",\n",
    "            \"sen_log\", \"hero_id\", \"kills_log\", \"towers_killed\", \"health\", \"xp_reasons\", \"randomed\",\n",
    "            \"x\", \"gold_t\", \"rune_pickups\", \"level\", \"lh_t\", \"dn_t\", \"actions\", \"nearby_creep_death_count\",\n",
    "            \"denies\", \"observers_placed\", \"times\", \"stuns\", \"deaths\", \"gold\", \"roshans_killed\"\n",
    "        ]\n",
    "        \n",
    "        for field in required_fields:\n",
    "            if field in player:\n",
    "                player_data[field] = player[field]\n",
    "\n",
    "        # 展开需要的嵌套字典（但不展开指定字段）\n",
    "        flat_player_data = flatten_dict(player_data, prefix=f\"players-{i}\")\n",
    "        data.update(flat_player_data)\n",
    "\n",
    "    return data\n",
    "\n",
    "def jsonl_to_csv(jsonl_file_path, csv_file_path):\n",
    "    \"\"\"\n",
    "    将JSONL文件转换为CSV文件，提取并展开每一行中的所有players数据。\n",
    "    \"\"\"\n",
    "    all_fieldnames = set()\n",
    "    \n",
    "    # 第一次遍历：确定完整的字段名\n",
    "    with open(jsonl_file_path, 'r') as jsonl_file:\n",
    "        for line in jsonl_file:\n",
    "            json_object = json.loads(line.strip())\n",
    "            processed_data = extract_players(json_object)\n",
    "            all_fieldnames.update(processed_data.keys())\n",
    "    \n",
    "    # 排序字段名，确保一致性\n",
    "    all_fieldnames = sorted(all_fieldnames)\n",
    "    \n",
    "    # 第二次遍历：将数据写入CSV文件\n",
    "    with open(jsonl_file_path, 'r') as jsonl_file, open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        csv_writer = csv.DictWriter(csv_file, fieldnames=all_fieldnames)\n",
    "        csv_writer.writeheader()\n",
    "        for line in jsonl_file:\n",
    "            json_object = json.loads(line.strip())\n",
    "            processed_data = extract_players(json_object)\n",
    "            csv_writer.writerow(processed_data)\n",
    "\n",
    "# 使用\n",
    "PATH_TO_DATA = '../data/'\n",
    "jsonl_file_path = os.path.join(PATH_TO_DATA, 'input_test.jsonl')\n",
    "csv_file_path = os.path.join(PATH_TO_DATA, 'data_extract/players_table_simpleversion.csv')\n",
    "jsonl_to_csv(jsonl_file_path, csv_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
