{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下一阶段的基本任务为：在前期获取到的数据上初步对随机森林模型进行超参数调优，使用调好的超参数进行特征重要性评估，选取 top k 个重要性较高的特征进行训练，观察结果和使用所有特征进行训练是否有较大差别。\n",
    "\n",
    "其次，进行特征组合，例如 KDA 等数据的进一步计算，添加一系列特征。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = './data/'\n",
    "\n",
    "# 将 'match_id_hash' 作为索引，'radiant_win' 作为标签\n",
    "train_data_path = os.path.join(PATH_TO_DATA, 'Dota_data_v1.0.csv')\n",
    "df_train = pd.read_csv(train_data_path, index_col='match_id_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'radiant_win' in df_train:\n",
    "    df_y = df_train['radiant_win']\n",
    "    del df_train['radiant_win']\n",
    "else:\n",
    "    print('No target')\n",
    "    df_y = None\n",
    "\n",
    "y = df_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看所有列名\n",
    "del df_train['game_time.1']\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df_train\n",
    "\n",
    "# 删除从 'total_teamfight_time' 开始的所有列\n",
    "df_X = df_X.iloc[:, 0:df_X.columns.get_loc('total_teamfight_time')]\n",
    "X = df_X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于调参的参数空间\n",
    "param_dist = {\n",
    "    'n_estimators': Integer(10, 200),\n",
    "    'max_depth': Integer(1, 200),\n",
    "    'min_samples_split': Integer(2, 10),\n",
    "    'min_samples_leaf': Integer(1, 10),\n",
    "}\n",
    "\n",
    "# 交叉验证\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)\n",
    "\n",
    "# 随机森林\n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state=17, criterion='log_loss',\n",
    "                            class_weight='balanced')\n",
    "\n",
    "# 贝叶斯优化\n",
    "opt = BayesSearchCV(\n",
    "    rf,\n",
    "    param_dist,\n",
    "    n_iter=20,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    random_state=17\n",
    ")\n",
    "opt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存贝叶斯优化过程\n",
    "results = pd.DataFrame(opt.cv_results_)\n",
    "results['mean_test_score'] = -results['mean_test_score']\n",
    "results['mean_train_score'] = -results['mean_train_score']\n",
    "results['n_estimators'] = results['param_n_estimators']\n",
    "results['max_depth'] = results['param_max_depth']\n",
    "results['min_samples_split'] = results['param_min_samples_split']\n",
    "results['min_samples_leaf'] = results['param_min_samples_leaf']\n",
    "results = results.sort_values('mean_test_score', ascending=False)\n",
    "results = results.drop(columns=['param_n_estimators', 'param_max_depth',\n",
    "                                'param_min_samples_split', 'param_min_samples_leaf'])\n",
    "results = results.reset_index(drop=True)\n",
    "results.to_csv('./results/RF_bayes_search_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best params & Best score', opt.best_params_, opt.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(class_weight='balanced', criterion='log_loss',\n",
    "                            max_depth=28, min_samples_leaf=8, min_samples_split=6,\n",
    "                            n_estimators=200, n_jobs=-1, random_state=17)\n",
    "\n",
    "# 使用交叉验证评估模型\n",
    "cv_scores = cross_val_score(rf, X, y, cv=cv, scoring='roc_auc')\n",
    "print('CV scores', cv_scores)\n",
    "print(f'CV mean: {cv_scores.mean()}, CV std: {cv_scores.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 scikit-learn 的 feature_importances_ 属性来获取特征重要性\n",
    "rf.fit(X, y)\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "for i, imp in enumerate(importances):\n",
    "    print(f'{df_X.columns[i]}: {imp}')\n",
    "\n",
    "# 在所有特征中，筛选出属于前150个特征的行，并可视化\n",
    "df_fi = pd.DataFrame({'Feature': df_X.columns, 'importance': importances})\n",
    "df_fi = df_fi.sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "df_fi = df_fi.iloc[:150]\n",
    "\n",
    "plt.figure(figsize=(14,28))\n",
    "sns.barplot(x=\"importance\", y=\"Feature\", data=df_fi)\n",
    "plt.title('Features importance')\n",
    "plt.tight_layout()\n",
    "plt.savefig('FI-Simple.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用重要性排名前 150 的特征进行训练\n",
    "index = np.argsort(importances)[::-1][:150]\n",
    "X_new = X[:, index]\n",
    "\n",
    "cv_scores = cross_val_score(rf, X_new, y, cv=cv, scoring='roc_auc')\n",
    "print('CV scores', cv_scores)\n",
    "print(f'CV mean: {cv_scores.mean()}, CV std: {cv_scores.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.argsort(importances)[::-1][:200]\n",
    "X_new = X[:, index]\n",
    "\n",
    "cv_scores = cross_val_score(rf, X_new, y, cv=cv, scoring='roc_auc')\n",
    "print('CV scores', cv_scores)\n",
    "print(f'CV mean: {cv_scores.mean()}, CV std: {cv_scores.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用特征重要性大于 0.001 的特征进行训练\n",
    "index = np.where(importances > 0.001)[0]\n",
    "X_new = X[:, index]\n",
    "\n",
    "cv_scores = cross_val_score(rf, X_new, y, cv=cv, scoring='roc_auc')\n",
    "print('CV scores', cv_scores)\n",
    "print(f'CV mean: {cv_scores.mean()}, CV std: {cv_scores.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 OOB 获取特征重要性\n",
    "rf = RandomForestClassifier(class_weight='balanced', criterion='log_loss',\n",
    "                            max_depth=28, min_samples_leaf=8, min_samples_split=6,\n",
    "                            n_estimators=200, n_jobs=-1, random_state=17, oob_score=True)\n",
    "\n",
    "rf.fit(X, y)\n",
    "\n",
    "# 查看基于OOB的性能\n",
    "print(f\"OOB Score: {rf.oob_score_}\")  # rf.oob_score_ 表示模型在 OOB 样本上的基准性能。\n",
    "\n",
    "def permutation_importance_oob(model, X_train, y_train):\n",
    "    \"\"\" 计算基于 OOB 误差的特征重要性。\n",
    "\n",
    "    parameter:\n",
    "        1. model   : 训练好的随机森林模型\n",
    "        2. X_train : 训练集特征\n",
    "        3. y_train : 训练集标签\n",
    "    \"\"\"\n",
    "    # 初始化变量\n",
    "    base_oob_score = model.oob_score_  # 基准OOB分数\n",
    "    feature_importances = np.zeros(X_train.shape[1])  # 保存特征重要性\n",
    "\n",
    "    # 遍历每个特征\n",
    "    for col in tqdm(range(X_train.shape[1])):\n",
    "        X_train_permuted = X_train.copy()  # 创建训练集副本\n",
    "        np.random.shuffle(X_train_permuted[:, col])  # 随机打乱某个特征列\n",
    "\n",
    "        # 用打乱特征后的训练集重新计算OOB得分\n",
    "        model.fit(X_train_permuted, y_train)\n",
    "        oob_score_permuted = model.oob_score_\n",
    "\n",
    "        # 计算 OOB 误差的变化\n",
    "        feature_importances[col] = base_oob_score - oob_score_permuted  # 分数下降越多，特征越重要\n",
    "\n",
    "    return feature_importances\n",
    "\n",
    "# 调用函数计算特征重要性\n",
    "oob_importances = permutation_importance_oob(rf, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出结果\n",
    "for i, importance in enumerate(oob_importances):\n",
    "    print(f\"Feature {i}: OOB Importance {importance}\")\n",
    "\n",
    "\n",
    "# 在所有特征中，筛选出属于前150个特征的行，并可视化\n",
    "df_fi = pd.DataFrame({'Feature': df_X.columns, 'importance': importances})\n",
    "df_fi = df_fi.sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "df_fi = df_fi.iloc[:150]\n",
    "\n",
    "plt.figure(figsize=(14,28))\n",
    "sns.barplot(x=\"importance\", y=\"Feature\", data=df_fi)\n",
    "plt.title('Features importance')\n",
    "plt.tight_layout()\n",
    "plt.savefig('FI-OBB.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用网格搜索进行超参数调优\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [None, 10, 15, 20, 30, 40],\n",
    "    'min_samples_split': [20, 25, 30, 35],\n",
    "    'min_samples_leaf': [20, 25, 30, 35, 40],\n",
    "}\n",
    "\n",
    "# 统计训练时间\n",
    "start_time = datetime.now()\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X, y)\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('Training took: ', end_time - start_time)\n",
    "print('Best params & Best score', grid_search.best_params_, grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制网格搜索结果热力图\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "scores = np.array(results.mean_test_score).reshape(6, 4, 5, 5)\n",
    "scores = scores.mean(axis=1)\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(scores.mean(axis=0), annot=True, fmt='.4f', xticklabels=param_grid['min_samples_leaf'],\n",
    "            yticklabels=param_grid['min_samples_split'])\n",
    "\n",
    "plt.xlabel('min_samples_leaf')\n",
    "plt.ylabel('min_samples_split')\n",
    "plt.title('ROC_AUC score')\n",
    "plt.tight_layout()\n",
    "plt.savefig('GridSearch.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用随机搜索进行超参数调优\n",
    "param_dist = {\n",
    "    'n_estimators': sp_randint(50, 200),\n",
    "    'max_depth': [None] + list(sp_randint(10, 20).rvs(10)),\n",
    "    'min_samples_leaf': sp_randint(1, 5)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=20,\n",
    "                                      cv=cv, scoring='roc_auc', n_jobs=-1, random_state=17)\n",
    "random_search.fit(X, y)\n",
    "\n",
    "print(random_search.best_params_, random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制随机搜索结果热力图\n",
    "results = pd.DataFrame(random_search.cv_results_)\n",
    "scores = np.array(results.mean_test_score).reshape(10, 5, 4)\n",
    "scores = scores.mean(axis=0)\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(scores, annot=True, fmt='.4f', xticklabels=param_dist['max_depth'],\n",
    "            yticklabels=param_dist['min_samples_leaf'])\n",
    "\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('min_samples_leaf')\n",
    "plt.title('ROC_AUC score')\n",
    "plt.tight_layout()\n",
    "plt.savefig('RandomSearch.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dota",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
