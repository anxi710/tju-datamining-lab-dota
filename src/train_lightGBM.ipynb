{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #to access files\n",
    "import pandas as pd #to work with dataframes\n",
    "import numpy as np #just a tradition\n",
    "from sklearn.model_selection import StratifiedKFold,train_test_split #for cross-validation\n",
    "from sklearn.metrics import roc_auc_score #this is we are trying to increase\n",
    "import matplotlib.pyplot as plt #we will plot something at the end)\n",
    "import seaborn as sns #same reason\n",
    "import lightgbm as lgb #the model we gonna use\n",
    "import optuna #超参数调优库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = './data/'\n",
    "\n",
    "# 将 'match_id_hash' 作为索引，'radiant_win' 作为标签\n",
    "train_data_path = os.path.join(PATH_TO_DATA, 'Dota_data_v1.0.csv')\n",
    "test_data_path = os.path.join(PATH_TO_DATA, 'test_data_v1.1.csv')\n",
    "df_train = pd.read_csv(train_data_path, index_col='match_id_hash')\n",
    "df_test = pd.read_csv(test_data_path, index_col='match_id_hash')\n",
    "#删掉多余的列\n",
    "df_train = df_train.drop(columns=['game_time.1'])\n",
    "\n",
    "df_test_features = pd.read_csv(os.path.join(PATH_TO_DATA, 'test_features.csv'),\n",
    "                               index_col='match_id_hash')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练集数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'radiant_win' in df_train:\n",
    "    df_y_train = df_train['radiant_win']\n",
    "    del df_train['radiant_win']\n",
    "else:\n",
    "    print('No target')\n",
    "    df_y_train = None\n",
    "\n",
    "y_train = df_y_train.to_numpy()\n",
    "\n",
    "df_X_train = df_train\n",
    "\n",
    "# 删除从 'total_teamfight_time' 开始的所有列\n",
    "df_X_train = df_X_train.iloc[:, 0:df_X_train.columns.get_loc('total_teamfight_time')]\n",
    "X_train = df_X_train.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试集数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'radiant_win' in df_test:\n",
    "    df_y_test = df_test['radiant_win']\n",
    "    del df_test['radiant_win']\n",
    "else:\n",
    "    print('No target')\n",
    "    df_y_test = None\n",
    "\n",
    "y_test = df_y_test.to_numpy()\n",
    "\n",
    "df_X_test = df_test\n",
    "\n",
    "# 删除从 'total_teamfight_time' 开始的所有列\n",
    "df_X_test = df_X_test.iloc[:, 0:df_X_test.columns.get_loc('total_teamfight_time')]\n",
    "X_test = df_X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(X_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "nan_positions_train = np.where(np.isnan(y_train), 'NaN', y_train)\n",
    "print(nan_positions_train)\n",
    "nan_positions = np.where(np.isnan(y_test), 'NaN', y_test)\n",
    "print(nan_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据集分割为训练集和测试集，80% 用于训练，20% 用于测试\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建 LightGBM 数据集\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lightGBM 调用超参数调优库optuna进行调试:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义目标函数\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', -1, 10),\n",
    "        #'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 50),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.5, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.5, 1.0),\n",
    "        'verbosity': -1 , # 控制训练过程中的输出级别，表示不输出信息\n",
    "        'num_round' : trial.suggest_int('num_round', 200, 800)\n",
    "    }\n",
    "\n",
    "    # params = {\n",
    "    #     'boosting_type': 'gbdt',\n",
    "    #     'objective': 'binary',\n",
    "    #     'metric': 'auc',\n",
    "    #     'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1, log=True),\n",
    "    #     'num_leaves': trial.suggest_int('num_leaves', 10, 100),\n",
    "    #     'max_depth': trial.suggest_int('max_depth', -1, 10),\n",
    "    #     #'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 50),\n",
    "    #     'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
    "    #     'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
    "    #     'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "    #     'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "    #     'min_gain_to_split': trial.suggest_float('min_gain_to_split', 0.0, 1.0),\n",
    "    #     'min_sum_hessian_in_leaf': trial.suggest_float('min_sum_hessian_in_leaf', 1e-5, 10.0, log=True),\n",
    "    #     'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "    #     'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "    #     'verbosity': -1  # 控制训练过程中的输出级别，表示不输出信息\n",
    "    # }\n",
    "\n",
    "    # 训练模型\n",
    "\n",
    "    bst = lgb.train(params, train_data, valid_sets=[test_data],callbacks=[lgb.early_stopping(30)])\n",
    "\n",
    "    # 在测试集上进行预测\n",
    "    y_pred_prob = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "\n",
    "    # 计算 ROC AUC 分数\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "    return roc_auc\n",
    "\n",
    "# 创建 Optuna 研究对象\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=200)\n",
    "\n",
    "# 输出最优超参数\n",
    "print(\"Best trial: score {},\\nparams {}\".format(study.best_trial.value, study.best_trial.params))\n",
    "\n",
    "# 使用最优超参数进行最终训练\n",
    "best_params = study.best_trial.params\n",
    "best_params['verbosity'] = -1  # 控制训练过程中的输出级别，表示要输出信息\n",
    "\n",
    "# 训练最终模型\n",
    "num_round = 100\n",
    "bst = lgb.train(best_params, train_data, num_round, valid_sets=[test_data],callbacks=[lgb.early_stopping(30)])\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred_prob = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "\n",
    "# 计算 ROC AUC 分数\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(f'ROC AUC Score with best params: {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置 LightGBM 参数\n",
    "# params = {\n",
    "#     'boosting_type': 'gbdt',\n",
    "#     'objective': 'binary',\n",
    "#     'metric': 'auc',\n",
    "#     'learning_rate': 0.023508897569229955,\n",
    "#     'num_leaves': 82,\n",
    "#     'max_depth': -1,\n",
    "#     'feature_fraction': 0.5206648048699497,\n",
    "#     'bagging_fraction': 0.6432060922386999,\n",
    "#     'num_round': 499\n",
    "# }\n",
    "#score=0.812\n",
    "\n",
    "\n",
    "params={\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.0531121462757666, \n",
    "    'num_leaves': 67, \n",
    "    'max_depth': 6, \n",
    "    'feature_fraction': 0.5208432697923645, \n",
    "    'bagging_fraction': 0.8069692225513229, \n",
    "    'num_round': 664\n",
    "        }\n",
    "#score=0.814\n",
    "\n",
    "\n",
    "# params = {\n",
    "#     'boosting_type' : 'gbdt',  # 梯度提升决策树，一种利用残差的多决策树集成学习\n",
    "#     'objective' : 'binary',    # 二分类\n",
    "#     'metric' : 'auc',          # 模型评估指标\n",
    "#     #'num_iterations' : 100,   # 生成多少棵树，即追逐残差多少次\n",
    "#     'learning_rate': 0.01,\n",
    "#     #下面有控制决策树叶子结点最多最少，深度最多最少的参数，均采用default\n",
    "#     'num_leaves' : 31, #最大叶子结点数\n",
    "#     'max_depth' : -1, #不限制最大参数\n",
    "#     'min_data_in_leaf' : 20, #一个叶子结点中最小的样本量，防止过度细的分类而过拟合\n",
    "#     'feature_fraction' : 0.9, #每次构建树时用于选择的特征的比例，不选择1防止过拟合\n",
    "#     'bagging_fraction' : 0.8, #每次迭代时用于训练的数据的比例，不选择1(全部样本)防止过拟合\n",
    "#     'verbosity': 1 #控制训练过程中的输出级别，表示要输出信息\n",
    "# }\n",
    "#score=0.769\n",
    "\n",
    "# 训练模型\n",
    "bst = lgb.train(params, train_data, valid_sets=[test_data],callbacks=[lgb.early_stopping(30)])\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred_prob = bst.predict(X_test, num_iteration=bst.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算 ROC AUC 分数\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(f'ROC AUC Score: {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打包数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame({'radiant_win_prob': y_pred_prob},\n",
    "                                 index=df_test_features.index)\n",
    "\n",
    "df_submission.to_csv(\"./data/submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
